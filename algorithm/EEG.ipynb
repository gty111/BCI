{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyeeg as pe\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import time\n",
    "import random\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits=5\n",
    "data_num = 7\n",
    "band = [4,8,12,16,25,45] #5 bands\n",
    "window_size = 1000 #Averaging band power of 2 sec\n",
    "step_size = 10 #Each 0.04 sec update once\n",
    "sample_rate = 500 #Sampling rate of 500 Hz\n",
    "features_num = 11\n",
    "feature_name = ['4-8Hz theta','8-12Hz alpha','12-16Hz lowbeta','16-25 highbeta','25-45Hz gamma','skew','std','mean','max-min','max','min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "data_raw=[]\n",
    "for i in range(data_num):\n",
    "    data.append(pd.read_csv(\"data\"+str(i)+\".txt\",sep=','))\n",
    "    data[-1] = data[-1][pd.isnull(data[-1]['RAW'])==False]\n",
    "    #tag = data['MOOD'].replace([0],[-1])\n",
    "    #data['MOOD'] = tag\n",
    "    data_raw.append(np.array(data[-1]['RAW']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "除了脑电波原有的5个频段特征\n",
    "加入6个统计特征，偏度，方差，均值，最大值-最小值,最大值，最小值\n",
    "'''\n",
    "def FFT(data_,num_,band=[4,8,12,16,25,45],window_size=1000,step_size=50,sample_rate=500):\n",
    "    start = 0\n",
    "    shape = data_.shape[0]\n",
    "    out_shape = (shape - window_size)// step_size + 1\n",
    "    output = np.zeros(shape=(out_shape,features_num+1)) \n",
    "    num = 0\n",
    "    while start + window_size < data_.shape[0]:\n",
    "        X = data_[start:start+window_size]\n",
    "        Y = pe.bin_power(X, band, sample_rate)\n",
    "        output_each = list(Y[1])\n",
    "        output_each.extend([pd.Series(X).skew(),X.std(),X.mean(),X.max()-X.min(),X.max(),X.min(),])#加入统计特征\n",
    "        output_each.append(data[num_].iloc[start+window_size-1,11])\n",
    "        output[num] = output_each\n",
    "        start += step_size\n",
    "        num+=1\n",
    "    np.save('output'+str(num_),output, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data_num):\n",
    "    FFT(data_raw[i],i,band,window_size,step_size,sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39355, 12)\n",
      "(31187, 12)\n",
      "(22766, 12)\n",
      "(40016, 12)\n",
      "(32668, 12)\n",
      "(22496, 12)\n",
      "(30213, 12)\n"
     ]
    }
   ],
   "source": [
    "output=[]\n",
    "for i in range(data_num):\n",
    "    output.append(np.load(open('output'+str(i)+'.npy','rb'),allow_pickle=True))\n",
    "    print(output[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218701, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_all = []\n",
    "for i in range(data_num):\n",
    "    output_all.append(output[i])\n",
    "output_all = np.concatenate(output_all)\n",
    "output_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(output_all).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n'n_estimators':2048,\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'num_iterations':10000,\n",
    "    'early_stopping_rounds': 100\n",
    "}\n",
    "'''\n",
    "'n_estimators':2048,\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:150: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:155: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 36124, number of negative: 138836\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 174960, number of used features: 11\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206470 -> initscore=-1.346336\n",
      "[LightGBM] [Info] Start training from score -1.346336\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.30463\tvalid_1's binary_logloss: 0.310034\n",
      "[200]\ttraining's binary_logloss: 0.242426\tvalid_1's binary_logloss: 0.25153\n",
      "[300]\ttraining's binary_logloss: 0.198933\tvalid_1's binary_logloss: 0.211214\n",
      "[400]\ttraining's binary_logloss: 0.166225\tvalid_1's binary_logloss: 0.18082\n",
      "[500]\ttraining's binary_logloss: 0.14312\tvalid_1's binary_logloss: 0.159814\n",
      "[600]\ttraining's binary_logloss: 0.123412\tvalid_1's binary_logloss: 0.14198\n",
      "[700]\ttraining's binary_logloss: 0.107901\tvalid_1's binary_logloss: 0.127795\n",
      "[800]\ttraining's binary_logloss: 0.0948667\tvalid_1's binary_logloss: 0.116096\n",
      "[900]\ttraining's binary_logloss: 0.0846451\tvalid_1's binary_logloss: 0.106957\n",
      "[1000]\ttraining's binary_logloss: 0.0760758\tvalid_1's binary_logloss: 0.099554\n",
      "[1100]\ttraining's binary_logloss: 0.0673317\tvalid_1's binary_logloss: 0.0920211\n",
      "[1200]\ttraining's binary_logloss: 0.0603469\tvalid_1's binary_logloss: 0.0859506\n",
      "[1300]\ttraining's binary_logloss: 0.0546239\tvalid_1's binary_logloss: 0.0809268\n",
      "[1400]\ttraining's binary_logloss: 0.0497373\tvalid_1's binary_logloss: 0.0768732\n",
      "[1500]\ttraining's binary_logloss: 0.0452932\tvalid_1's binary_logloss: 0.0733715\n",
      "[1600]\ttraining's binary_logloss: 0.041519\tvalid_1's binary_logloss: 0.0703838\n",
      "[1700]\ttraining's binary_logloss: 0.0381408\tvalid_1's binary_logloss: 0.067758\n",
      "[1800]\ttraining's binary_logloss: 0.0348703\tvalid_1's binary_logloss: 0.0651237\n",
      "[1900]\ttraining's binary_logloss: 0.0318125\tvalid_1's binary_logloss: 0.0627296\n",
      "[2000]\ttraining's binary_logloss: 0.029004\tvalid_1's binary_logloss: 0.0603581\n",
      "[2100]\ttraining's binary_logloss: 0.0261631\tvalid_1's binary_logloss: 0.0579762\n",
      "[2200]\ttraining's binary_logloss: 0.0238583\tvalid_1's binary_logloss: 0.0562606\n",
      "[2300]\ttraining's binary_logloss: 0.0219453\tvalid_1's binary_logloss: 0.0546849\n",
      "[2400]\ttraining's binary_logloss: 0.0202087\tvalid_1's binary_logloss: 0.0533786\n",
      "[2500]\ttraining's binary_logloss: 0.0182354\tvalid_1's binary_logloss: 0.0517428\n",
      "[2600]\ttraining's binary_logloss: 0.0167658\tvalid_1's binary_logloss: 0.0507216\n",
      "[2700]\ttraining's binary_logloss: 0.0153024\tvalid_1's binary_logloss: 0.0496102\n",
      "[2800]\ttraining's binary_logloss: 0.0140334\tvalid_1's binary_logloss: 0.0486912\n",
      "[2900]\ttraining's binary_logloss: 0.0128852\tvalid_1's binary_logloss: 0.0479795\n",
      "[3000]\ttraining's binary_logloss: 0.0119369\tvalid_1's binary_logloss: 0.0472337\n",
      "[3100]\ttraining's binary_logloss: 0.0109065\tvalid_1's binary_logloss: 0.0463974\n",
      "[3200]\ttraining's binary_logloss: 0.00998161\tvalid_1's binary_logloss: 0.0456237\n",
      "[3300]\ttraining's binary_logloss: 0.00910649\tvalid_1's binary_logloss: 0.0449754\n",
      "[3400]\ttraining's binary_logloss: 0.00838422\tvalid_1's binary_logloss: 0.044513\n",
      "[3500]\ttraining's binary_logloss: 0.00772698\tvalid_1's binary_logloss: 0.0440727\n",
      "[3600]\ttraining's binary_logloss: 0.00711155\tvalid_1's binary_logloss: 0.0436382\n",
      "[3700]\ttraining's binary_logloss: 0.00657932\tvalid_1's binary_logloss: 0.0432643\n",
      "[3800]\ttraining's binary_logloss: 0.00606093\tvalid_1's binary_logloss: 0.0429279\n",
      "[3900]\ttraining's binary_logloss: 0.00558832\tvalid_1's binary_logloss: 0.0427126\n",
      "[4000]\ttraining's binary_logloss: 0.0051231\tvalid_1's binary_logloss: 0.0424422\n",
      "[4100]\ttraining's binary_logloss: 0.00471275\tvalid_1's binary_logloss: 0.0421443\n",
      "[4200]\ttraining's binary_logloss: 0.00437289\tvalid_1's binary_logloss: 0.0419731\n",
      "[4300]\ttraining's binary_logloss: 0.00400519\tvalid_1's binary_logloss: 0.0417677\n",
      "[4400]\ttraining's binary_logloss: 0.00368359\tvalid_1's binary_logloss: 0.0417102\n",
      "[4500]\ttraining's binary_logloss: 0.00337571\tvalid_1's binary_logloss: 0.0415285\n",
      "[4600]\ttraining's binary_logloss: 0.0031175\tvalid_1's binary_logloss: 0.0414889\n",
      "[4700]\ttraining's binary_logloss: 0.00286686\tvalid_1's binary_logloss: 0.0414759\n",
      "[4800]\ttraining's binary_logloss: 0.00265105\tvalid_1's binary_logloss: 0.0414421\n",
      "[4900]\ttraining's binary_logloss: 0.00244211\tvalid_1's binary_logloss: 0.0413521\n",
      "Early stopping, best iteration is:\n",
      "[4881]\ttraining's binary_logloss: 0.00248169\tvalid_1's binary_logloss: 0.0413338\n",
      "0 val f1 [0.99158121 0.96694261]\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 36125, number of negative: 138836\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 174961, number of used features: 11\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206475 -> initscore=-1.346308\n",
      "[LightGBM] [Info] Start training from score -1.346308\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.301716\tvalid_1's binary_logloss: 0.309654\n",
      "[200]\ttraining's binary_logloss: 0.237689\tvalid_1's binary_logloss: 0.249027\n",
      "[300]\ttraining's binary_logloss: 0.195369\tvalid_1's binary_logloss: 0.20997\n",
      "[400]\ttraining's binary_logloss: 0.165689\tvalid_1's binary_logloss: 0.182712\n",
      "[500]\ttraining's binary_logloss: 0.141769\tvalid_1's binary_logloss: 0.160408\n",
      "[600]\ttraining's binary_logloss: 0.122496\tvalid_1's binary_logloss: 0.143032\n",
      "[700]\ttraining's binary_logloss: 0.107921\tvalid_1's binary_logloss: 0.129881\n",
      "[800]\ttraining's binary_logloss: 0.0942029\tvalid_1's binary_logloss: 0.117465\n",
      "[900]\ttraining's binary_logloss: 0.0837491\tvalid_1's binary_logloss: 0.108178\n",
      "[1000]\ttraining's binary_logloss: 0.0744972\tvalid_1's binary_logloss: 0.0998917\n",
      "[1100]\ttraining's binary_logloss: 0.0667395\tvalid_1's binary_logloss: 0.0932863\n",
      "[1200]\ttraining's binary_logloss: 0.0598864\tvalid_1's binary_logloss: 0.087263\n",
      "[1300]\ttraining's binary_logloss: 0.0540937\tvalid_1's binary_logloss: 0.0823405\n",
      "[1400]\ttraining's binary_logloss: 0.0486587\tvalid_1's binary_logloss: 0.0779099\n",
      "[1500]\ttraining's binary_logloss: 0.0442183\tvalid_1's binary_logloss: 0.0742636\n",
      "[1600]\ttraining's binary_logloss: 0.0405111\tvalid_1's binary_logloss: 0.0713926\n",
      "[1700]\ttraining's binary_logloss: 0.0364432\tvalid_1's binary_logloss: 0.0679268\n",
      "[1800]\ttraining's binary_logloss: 0.0331554\tvalid_1's binary_logloss: 0.0652514\n",
      "[1900]\ttraining's binary_logloss: 0.0298323\tvalid_1's binary_logloss: 0.0625835\n",
      "[2000]\ttraining's binary_logloss: 0.0271256\tvalid_1's binary_logloss: 0.0605082\n",
      "[2100]\ttraining's binary_logloss: 0.0248753\tvalid_1's binary_logloss: 0.0589387\n",
      "[2200]\ttraining's binary_logloss: 0.0226476\tvalid_1's binary_logloss: 0.0571277\n",
      "[2300]\ttraining's binary_logloss: 0.0207772\tvalid_1's binary_logloss: 0.0556118\n",
      "[2400]\ttraining's binary_logloss: 0.0189785\tvalid_1's binary_logloss: 0.0542857\n",
      "[2500]\ttraining's binary_logloss: 0.0174773\tvalid_1's binary_logloss: 0.0532441\n",
      "[2600]\ttraining's binary_logloss: 0.0160094\tvalid_1's binary_logloss: 0.0523122\n",
      "[2700]\ttraining's binary_logloss: 0.0147499\tvalid_1's binary_logloss: 0.051396\n",
      "[2800]\ttraining's binary_logloss: 0.0135302\tvalid_1's binary_logloss: 0.0504492\n",
      "[2900]\ttraining's binary_logloss: 0.0124732\tvalid_1's binary_logloss: 0.0498483\n",
      "[3000]\ttraining's binary_logloss: 0.0113541\tvalid_1's binary_logloss: 0.0491027\n",
      "[3100]\ttraining's binary_logloss: 0.0104477\tvalid_1's binary_logloss: 0.0485412\n",
      "[3200]\ttraining's binary_logloss: 0.00961075\tvalid_1's binary_logloss: 0.0479593\n",
      "[3300]\ttraining's binary_logloss: 0.00891402\tvalid_1's binary_logloss: 0.0475069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3400]\ttraining's binary_logloss: 0.00818883\tvalid_1's binary_logloss: 0.0472645\n",
      "[3500]\ttraining's binary_logloss: 0.00751406\tvalid_1's binary_logloss: 0.0470015\n",
      "[3600]\ttraining's binary_logloss: 0.00687554\tvalid_1's binary_logloss: 0.0467721\n",
      "[3700]\ttraining's binary_logloss: 0.00632437\tvalid_1's binary_logloss: 0.0464371\n",
      "[3800]\ttraining's binary_logloss: 0.00585207\tvalid_1's binary_logloss: 0.0461676\n",
      "[3900]\ttraining's binary_logloss: 0.0053655\tvalid_1's binary_logloss: 0.0458846\n",
      "[4000]\ttraining's binary_logloss: 0.0048891\tvalid_1's binary_logloss: 0.0456605\n",
      "[4100]\ttraining's binary_logloss: 0.00451578\tvalid_1's binary_logloss: 0.0454402\n",
      "[4200]\ttraining's binary_logloss: 0.00415206\tvalid_1's binary_logloss: 0.0452474\n",
      "[4300]\ttraining's binary_logloss: 0.00384326\tvalid_1's binary_logloss: 0.0451724\n",
      "[4400]\ttraining's binary_logloss: 0.00354501\tvalid_1's binary_logloss: 0.0451439\n",
      "Early stopping, best iteration is:\n",
      "[4346]\ttraining's binary_logloss: 0.00370371\tvalid_1's binary_logloss: 0.0451205\n",
      "1 val f1 [0.99072734 0.96345665]\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 36125, number of negative: 138836\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 174961, number of used features: 11\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206475 -> initscore=-1.346308\n",
      "[LightGBM] [Info] Start training from score -1.346308\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.301175\tvalid_1's binary_logloss: 0.309891\n",
      "[200]\ttraining's binary_logloss: 0.237716\tvalid_1's binary_logloss: 0.248993\n",
      "[300]\ttraining's binary_logloss: 0.197447\tvalid_1's binary_logloss: 0.211122\n",
      "[400]\ttraining's binary_logloss: 0.167768\tvalid_1's binary_logloss: 0.183728\n",
      "[500]\ttraining's binary_logloss: 0.145611\tvalid_1's binary_logloss: 0.16302\n",
      "[600]\ttraining's binary_logloss: 0.12454\tvalid_1's binary_logloss: 0.143336\n",
      "[700]\ttraining's binary_logloss: 0.109542\tvalid_1's binary_logloss: 0.129786\n",
      "[800]\ttraining's binary_logloss: 0.096691\tvalid_1's binary_logloss: 0.118376\n",
      "[900]\ttraining's binary_logloss: 0.0861854\tvalid_1's binary_logloss: 0.109153\n",
      "[1000]\ttraining's binary_logloss: 0.0771442\tvalid_1's binary_logloss: 0.101173\n",
      "[1100]\ttraining's binary_logloss: 0.069129\tvalid_1's binary_logloss: 0.0943533\n",
      "[1200]\ttraining's binary_logloss: 0.062195\tvalid_1's binary_logloss: 0.0884085\n",
      "[1300]\ttraining's binary_logloss: 0.0560535\tvalid_1's binary_logloss: 0.0831047\n",
      "[1400]\ttraining's binary_logloss: 0.0505377\tvalid_1's binary_logloss: 0.0782576\n",
      "[1500]\ttraining's binary_logloss: 0.0452698\tvalid_1's binary_logloss: 0.0738006\n",
      "[1600]\ttraining's binary_logloss: 0.0410935\tvalid_1's binary_logloss: 0.0703759\n",
      "[1700]\ttraining's binary_logloss: 0.0374744\tvalid_1's binary_logloss: 0.0674224\n",
      "[1800]\ttraining's binary_logloss: 0.0342102\tvalid_1's binary_logloss: 0.0648082\n",
      "[1900]\ttraining's binary_logloss: 0.0310802\tvalid_1's binary_logloss: 0.0621759\n",
      "[2000]\ttraining's binary_logloss: 0.0281678\tvalid_1's binary_logloss: 0.0597369\n",
      "[2100]\ttraining's binary_logloss: 0.0257639\tvalid_1's binary_logloss: 0.0578422\n",
      "[2200]\ttraining's binary_logloss: 0.0234415\tvalid_1's binary_logloss: 0.0559838\n",
      "[2300]\ttraining's binary_logloss: 0.0214261\tvalid_1's binary_logloss: 0.0544491\n",
      "[2400]\ttraining's binary_logloss: 0.0197913\tvalid_1's binary_logloss: 0.0531393\n",
      "[2500]\ttraining's binary_logloss: 0.0183198\tvalid_1's binary_logloss: 0.051971\n",
      "[2600]\ttraining's binary_logloss: 0.016612\tvalid_1's binary_logloss: 0.0506024\n",
      "[2700]\ttraining's binary_logloss: 0.0151061\tvalid_1's binary_logloss: 0.0495146\n",
      "[2800]\ttraining's binary_logloss: 0.0138882\tvalid_1's binary_logloss: 0.0485579\n",
      "[2900]\ttraining's binary_logloss: 0.012692\tvalid_1's binary_logloss: 0.0475809\n",
      "[3000]\ttraining's binary_logloss: 0.0116216\tvalid_1's binary_logloss: 0.0467371\n",
      "[3100]\ttraining's binary_logloss: 0.0106686\tvalid_1's binary_logloss: 0.0461953\n",
      "[3200]\ttraining's binary_logloss: 0.00983705\tvalid_1's binary_logloss: 0.0457363\n",
      "[3300]\ttraining's binary_logloss: 0.00905002\tvalid_1's binary_logloss: 0.0452968\n",
      "[3400]\ttraining's binary_logloss: 0.00833128\tvalid_1's binary_logloss: 0.0448902\n",
      "[3500]\ttraining's binary_logloss: 0.00759119\tvalid_1's binary_logloss: 0.0444048\n",
      "[3600]\ttraining's binary_logloss: 0.0069636\tvalid_1's binary_logloss: 0.0440109\n",
      "[3700]\ttraining's binary_logloss: 0.00641341\tvalid_1's binary_logloss: 0.0436818\n",
      "[3800]\ttraining's binary_logloss: 0.00590427\tvalid_1's binary_logloss: 0.0434383\n",
      "[3900]\ttraining's binary_logloss: 0.00547696\tvalid_1's binary_logloss: 0.0432225\n",
      "[4000]\ttraining's binary_logloss: 0.00499995\tvalid_1's binary_logloss: 0.0429866\n",
      "[4100]\ttraining's binary_logloss: 0.00461274\tvalid_1's binary_logloss: 0.0428823\n",
      "[4200]\ttraining's binary_logloss: 0.00427438\tvalid_1's binary_logloss: 0.042704\n",
      "[4300]\ttraining's binary_logloss: 0.00395249\tvalid_1's binary_logloss: 0.0426021\n",
      "[4400]\ttraining's binary_logloss: 0.00367474\tvalid_1's binary_logloss: 0.0424315\n",
      "[4500]\ttraining's binary_logloss: 0.0033888\tvalid_1's binary_logloss: 0.0423541\n",
      "[4600]\ttraining's binary_logloss: 0.00313325\tvalid_1's binary_logloss: 0.0422757\n",
      "[4700]\ttraining's binary_logloss: 0.00289456\tvalid_1's binary_logloss: 0.0422716\n",
      "[4800]\ttraining's binary_logloss: 0.00266324\tvalid_1's binary_logloss: 0.0421572\n",
      "[4900]\ttraining's binary_logloss: 0.00245111\tvalid_1's binary_logloss: 0.042157\n",
      "Early stopping, best iteration is:\n",
      "[4807]\ttraining's binary_logloss: 0.0026506\tvalid_1's binary_logloss: 0.0421384\n",
      "2 val f1 [0.9916369  0.96719005]\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 36125, number of negative: 138836\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 174961, number of used features: 11\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206475 -> initscore=-1.346308\n",
      "[LightGBM] [Info] Start training from score -1.346308\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.3006\tvalid_1's binary_logloss: 0.30511\n",
      "[200]\ttraining's binary_logloss: 0.24073\tvalid_1's binary_logloss: 0.24948\n",
      "[300]\ttraining's binary_logloss: 0.195994\tvalid_1's binary_logloss: 0.207282\n",
      "[400]\ttraining's binary_logloss: 0.164383\tvalid_1's binary_logloss: 0.177702\n",
      "[500]\ttraining's binary_logloss: 0.14131\tvalid_1's binary_logloss: 0.156706\n",
      "[600]\ttraining's binary_logloss: 0.121634\tvalid_1's binary_logloss: 0.138837\n",
      "[700]\ttraining's binary_logloss: 0.107752\tvalid_1's binary_logloss: 0.126477\n",
      "[800]\ttraining's binary_logloss: 0.0949644\tvalid_1's binary_logloss: 0.114808\n",
      "[900]\ttraining's binary_logloss: 0.0840268\tvalid_1's binary_logloss: 0.105033\n",
      "[1000]\ttraining's binary_logloss: 0.0754871\tvalid_1's binary_logloss: 0.097645\n",
      "[1100]\ttraining's binary_logloss: 0.0678922\tvalid_1's binary_logloss: 0.0911685\n",
      "[1200]\ttraining's binary_logloss: 0.0609172\tvalid_1's binary_logloss: 0.0853866\n",
      "[1300]\ttraining's binary_logloss: 0.0552156\tvalid_1's binary_logloss: 0.0807237\n",
      "[1400]\ttraining's binary_logloss: 0.0497156\tvalid_1's binary_logloss: 0.0761625\n",
      "[1500]\ttraining's binary_logloss: 0.0448887\tvalid_1's binary_logloss: 0.0721581\n",
      "[1600]\ttraining's binary_logloss: 0.0410189\tvalid_1's binary_logloss: 0.0691054\n",
      "[1700]\ttraining's binary_logloss: 0.0375105\tvalid_1's binary_logloss: 0.0663113\n",
      "[1800]\ttraining's binary_logloss: 0.0339351\tvalid_1's binary_logloss: 0.0634106\n",
      "[1900]\ttraining's binary_logloss: 0.0307153\tvalid_1's binary_logloss: 0.0608579\n",
      "[2000]\ttraining's binary_logloss: 0.0278554\tvalid_1's binary_logloss: 0.058701\n",
      "[2100]\ttraining's binary_logloss: 0.0254593\tvalid_1's binary_logloss: 0.0569663\n",
      "[2200]\ttraining's binary_logloss: 0.0233629\tvalid_1's binary_logloss: 0.0554272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2300]\ttraining's binary_logloss: 0.0212676\tvalid_1's binary_logloss: 0.0539308\n",
      "[2400]\ttraining's binary_logloss: 0.019527\tvalid_1's binary_logloss: 0.0526305\n",
      "[2500]\ttraining's binary_logloss: 0.0178369\tvalid_1's binary_logloss: 0.0512483\n",
      "[2600]\ttraining's binary_logloss: 0.0163754\tvalid_1's binary_logloss: 0.0501297\n",
      "[2700]\ttraining's binary_logloss: 0.0151154\tvalid_1's binary_logloss: 0.0492617\n",
      "[2800]\ttraining's binary_logloss: 0.0138664\tvalid_1's binary_logloss: 0.0482816\n",
      "[2900]\ttraining's binary_logloss: 0.0126774\tvalid_1's binary_logloss: 0.0473862\n",
      "[3000]\ttraining's binary_logloss: 0.0116046\tvalid_1's binary_logloss: 0.0465057\n",
      "[3100]\ttraining's binary_logloss: 0.0105965\tvalid_1's binary_logloss: 0.0457994\n",
      "[3200]\ttraining's binary_logloss: 0.0097324\tvalid_1's binary_logloss: 0.0452195\n",
      "[3300]\ttraining's binary_logloss: 0.00900663\tvalid_1's binary_logloss: 0.0449605\n",
      "[3400]\ttraining's binary_logloss: 0.00828803\tvalid_1's binary_logloss: 0.0445476\n",
      "[3500]\ttraining's binary_logloss: 0.00762687\tvalid_1's binary_logloss: 0.0442688\n",
      "[3600]\ttraining's binary_logloss: 0.00697683\tvalid_1's binary_logloss: 0.043839\n",
      "[3700]\ttraining's binary_logloss: 0.00640441\tvalid_1's binary_logloss: 0.0434212\n",
      "[3800]\ttraining's binary_logloss: 0.00589298\tvalid_1's binary_logloss: 0.0432936\n",
      "[3900]\ttraining's binary_logloss: 0.00539351\tvalid_1's binary_logloss: 0.0429774\n",
      "[4000]\ttraining's binary_logloss: 0.0049478\tvalid_1's binary_logloss: 0.042729\n",
      "[4100]\ttraining's binary_logloss: 0.00455182\tvalid_1's binary_logloss: 0.0425136\n",
      "[4200]\ttraining's binary_logloss: 0.00415906\tvalid_1's binary_logloss: 0.042521\n",
      "Early stopping, best iteration is:\n",
      "[4148]\ttraining's binary_logloss: 0.00435287\tvalid_1's binary_logloss: 0.0424506\n",
      "3 val f1 [0.99127195 0.96560294]\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 36125, number of negative: 138836\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 174961, number of used features: 11\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206475 -> initscore=-1.346308\n",
      "[LightGBM] [Info] Start training from score -1.346308\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.302662\tvalid_1's binary_logloss: 0.310263\n",
      "[200]\ttraining's binary_logloss: 0.241306\tvalid_1's binary_logloss: 0.253012\n",
      "[300]\ttraining's binary_logloss: 0.197065\tvalid_1's binary_logloss: 0.211014\n",
      "[400]\ttraining's binary_logloss: 0.164934\tvalid_1's binary_logloss: 0.181368\n",
      "[500]\ttraining's binary_logloss: 0.141588\tvalid_1's binary_logloss: 0.159446\n",
      "[600]\ttraining's binary_logloss: 0.12323\tvalid_1's binary_logloss: 0.142089\n",
      "[700]\ttraining's binary_logloss: 0.107642\tvalid_1's binary_logloss: 0.127791\n",
      "[800]\ttraining's binary_logloss: 0.095217\tvalid_1's binary_logloss: 0.116461\n",
      "[900]\ttraining's binary_logloss: 0.0854237\tvalid_1's binary_logloss: 0.108091\n",
      "[1000]\ttraining's binary_logloss: 0.0765279\tvalid_1's binary_logloss: 0.100128\n",
      "[1100]\ttraining's binary_logloss: 0.0684558\tvalid_1's binary_logloss: 0.0929868\n",
      "[1200]\ttraining's binary_logloss: 0.0613326\tvalid_1's binary_logloss: 0.0866692\n",
      "[1300]\ttraining's binary_logloss: 0.0549858\tvalid_1's binary_logloss: 0.0811984\n",
      "[1400]\ttraining's binary_logloss: 0.0502708\tvalid_1's binary_logloss: 0.0773457\n",
      "[1500]\ttraining's binary_logloss: 0.045389\tvalid_1's binary_logloss: 0.0732174\n",
      "[1600]\ttraining's binary_logloss: 0.0410481\tvalid_1's binary_logloss: 0.06924\n",
      "[1700]\ttraining's binary_logloss: 0.0371321\tvalid_1's binary_logloss: 0.0661357\n",
      "[1800]\ttraining's binary_logloss: 0.0339792\tvalid_1's binary_logloss: 0.0635434\n",
      "[1900]\ttraining's binary_logloss: 0.0309685\tvalid_1's binary_logloss: 0.0612567\n",
      "[2000]\ttraining's binary_logloss: 0.0282198\tvalid_1's binary_logloss: 0.0590259\n",
      "[2100]\ttraining's binary_logloss: 0.0256723\tvalid_1's binary_logloss: 0.0571272\n",
      "[2200]\ttraining's binary_logloss: 0.0234339\tvalid_1's binary_logloss: 0.0553934\n",
      "[2300]\ttraining's binary_logloss: 0.021383\tvalid_1's binary_logloss: 0.0536685\n",
      "[2400]\ttraining's binary_logloss: 0.0195673\tvalid_1's binary_logloss: 0.0524812\n",
      "[2500]\ttraining's binary_logloss: 0.0180541\tvalid_1's binary_logloss: 0.0514072\n",
      "[2600]\ttraining's binary_logloss: 0.0167956\tvalid_1's binary_logloss: 0.0504991\n",
      "[2700]\ttraining's binary_logloss: 0.0155388\tvalid_1's binary_logloss: 0.0496379\n",
      "[2800]\ttraining's binary_logloss: 0.0142206\tvalid_1's binary_logloss: 0.0485964\n",
      "[2900]\ttraining's binary_logloss: 0.013031\tvalid_1's binary_logloss: 0.0476947\n",
      "[3000]\ttraining's binary_logloss: 0.0119869\tvalid_1's binary_logloss: 0.0469778\n",
      "[3100]\ttraining's binary_logloss: 0.0110182\tvalid_1's binary_logloss: 0.0461858\n",
      "[3200]\ttraining's binary_logloss: 0.0100687\tvalid_1's binary_logloss: 0.0453597\n",
      "[3300]\ttraining's binary_logloss: 0.00929248\tvalid_1's binary_logloss: 0.0448856\n",
      "[3400]\ttraining's binary_logloss: 0.00850796\tvalid_1's binary_logloss: 0.0443205\n",
      "[3500]\ttraining's binary_logloss: 0.0078525\tvalid_1's binary_logloss: 0.0438004\n",
      "[3600]\ttraining's binary_logloss: 0.00722617\tvalid_1's binary_logloss: 0.0433282\n",
      "[3700]\ttraining's binary_logloss: 0.00670853\tvalid_1's binary_logloss: 0.0430336\n",
      "[3800]\ttraining's binary_logloss: 0.0061981\tvalid_1's binary_logloss: 0.0426968\n",
      "[3900]\ttraining's binary_logloss: 0.00569402\tvalid_1's binary_logloss: 0.0423432\n",
      "[4000]\ttraining's binary_logloss: 0.00526083\tvalid_1's binary_logloss: 0.0421222\n",
      "[4100]\ttraining's binary_logloss: 0.00482461\tvalid_1's binary_logloss: 0.0420348\n",
      "Early stopping, best iteration is:\n",
      "[4077]\ttraining's binary_logloss: 0.00489822\tvalid_1's binary_logloss: 0.0419716\n",
      "4 val f1 [0.99110678 0.96509795]\n"
     ]
    }
   ],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X = scaler.fit_transform(output_all[:,0:5])\n",
    "fold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=41)\n",
    "X = output_all[:,0:features_num]\n",
    "y = output_all[:,features_num]\n",
    "models = []\n",
    "oof = np.zeros((len(X)))\n",
    "for index,(train_idx,val_idx) in enumerate(fold.split(X, y)):\n",
    "    train_set = lgb.Dataset(X[train_idx],y[train_idx])\n",
    "    val_set = lgb.Dataset(X[val_idx],y[val_idx])\n",
    "    model = lgb.train(params,train_set,valid_sets=[train_set,val_set],verbose_eval=100,feature_name=feature_name)\n",
    "    models.append(model)\n",
    "    val_pred = model.predict(X[val_idx])\n",
    "    val_pred = np.round(val_pred)\n",
    "    oof[val_idx] = val_pred\n",
    "    val_y = y[val_idx]\n",
    "    print(index, 'val f1', metrics.f1_score(val_y, val_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oof f1 [0.99126475 0.96565953]\n"
     ]
    }
   ],
   "source": [
    "print('oof f1', metrics.f1_score(oof, y, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_splits):\n",
    "    joblib.dump(models[i],'lgb'+str(i)+'.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4-8Hz_theta',\n",
       " '8-12Hz_alpha',\n",
       " '12-16Hz_lowbeta',\n",
       " '16-25_highbeta',\n",
       " '25-45Hz_gamma',\n",
       " 'skew',\n",
       " 'std',\n",
       " 'mean',\n",
       " 'max-min',\n",
       " 'max',\n",
       " 'min']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].feature_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = []\n",
    "for index, model in enumerate(models):\n",
    "    df = pd.DataFrame()\n",
    "    df['name'] = model.feature_name()\n",
    "    df['score'] = model.feature_importance()\n",
    "    df['fold'] = index\n",
    "    ret.append(df)\n",
    "df = pd.concat(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max</td>\n",
       "      <td>16460.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>min</td>\n",
       "      <td>15842.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>std</td>\n",
       "      <td>13423.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>skew</td>\n",
       "      <td>13280.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max-min</td>\n",
       "      <td>12679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25-45Hz_gamma</td>\n",
       "      <td>11249.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4-8Hz_theta</td>\n",
       "      <td>10395.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8-12Hz_alpha</td>\n",
       "      <td>10385.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean</td>\n",
       "      <td>10168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12-16Hz_lowbeta</td>\n",
       "      <td>10105.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16-25_highbeta</td>\n",
       "      <td>9564.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name    score\n",
       "5               max  16460.8\n",
       "8               min  15842.8\n",
       "10              std  13423.4\n",
       "9              skew  13280.2\n",
       "6           max-min  12679.0\n",
       "2     25-45Hz_gamma  11249.2\n",
       "3       4-8Hz_theta  10395.4\n",
       "4      8-12Hz_alpha  10385.8\n",
       "7              mean  10168.0\n",
       "0   12-16Hz_lowbeta  10105.4\n",
       "1    16-25_highbeta   9564.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby('name', as_index=False)['score'].mean()\n",
    "df = df.sort_values(['score'], ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 val f1 [0.98469662 0.95932561]\n",
      "1 val f1 [0.98451113 0.95882894]\n",
      "2 val f1 [0.98433598 0.95830987]\n",
      "3 val f1 [0.98452014 0.95879028]\n",
      "4 val f1 [0.9842591  0.95812542]\n"
     ]
    }
   ],
   "source": [
    "#scaler = StandardScaler()\n",
    "#x = scaler.fit_transform(output_all[:,0:5])\n",
    "x = output_all[:,0:5]\n",
    "y = output_all[:,5]\n",
    "fold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=41)\n",
    "models = []\n",
    "oof = np.zeros((len(x)))\n",
    "for index, (train_idx, val_idx) in enumerate(fold.split(x, y)):\n",
    "    train_set_x,train_set_y = x[train_idx], y[train_idx]\n",
    "    val_set_x,val_set_y = x[val_idx], y[val_idx]\n",
    "    rfr = RandomForestClassifier(n_estimators=512, n_jobs=-1)\n",
    "    rfr.fit(train_set_x,train_set_y)\n",
    "    models.append(rfr)\n",
    "    val_pred = rfr.predict(val_set_x)\n",
    "    #val_pred = np.around(val_pred)\n",
    "    oof[val_idx] = val_pred\n",
    "    val_y = val_set_y\n",
    "    print(index, 'val f1', metrics.f1_score(val_y, val_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oof f1 [0.98446458 0.95867614]\n"
     ]
    }
   ],
   "source": [
    "print('oof f1', metrics.f1_score(oof, y, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22514058 0.19445062 0.17899713 0.17360194 0.22780974]\n",
      "[0.22391495 0.19484324 0.18136518 0.17383927 0.22603736]\n",
      "[0.22422827 0.1946285  0.17959088 0.17231861 0.22923375]\n",
      "[0.22357922 0.19330085 0.17954152 0.1750695  0.22850891]\n",
      "[0.22445352 0.19417766 0.18076557 0.17394622 0.22665703]\n"
     ]
    }
   ],
   "source": [
    "for i in models:    \n",
    "    print(i.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_splits):\n",
    "    joblib.dump(models[i],'rf'+str(i)+'.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.AdaBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 val f1 0.24572253143681716\n",
      "1 val f1 0.2323462414578588\n",
      "2 val f1 0.0999250562078441\n",
      "3 val f1 0.0989010989010989\n",
      "4 val f1 0.09327983951855566\n"
     ]
    }
   ],
   "source": [
    "x = output_all[:,0:5]\n",
    "y = output_all[:,5]\n",
    "fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=41)\n",
    "models = []\n",
    "oof = np.zeros((len(x)))\n",
    "for index, (train_idx, val_idx) in enumerate(fold.split(x, y)):\n",
    "    train_set_x,train_set_y = x[train_idx], y[train_idx]\n",
    "    val_set_x,val_set_y = x[val_idx], y[val_idx]\n",
    "    abr = AdaBoostRegressor(n_estimators=5000, learning_rate=0.01)\n",
    "    abr.fit(train_set_x,train_set_y)\n",
    "    val_pred = abr.predict(val_set_x)\n",
    "    val_pred = np.around(val_pred)\n",
    "    oof[val_idx] = val_pred\n",
    "    val_y = val_set_y\n",
    "    print(index, 'val f1', metrics.f1_score(val_y, val_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oof f1 0.16064590542099194\n"
     ]
    }
   ],
   "source": [
    "print('oof f1', metrics.f1_score(oof, y, average='binary'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
